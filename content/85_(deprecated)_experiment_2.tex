% Second, we changed the \textit{relationships and interactions} among items in the survey. In experiment 1, the different societal causes (items) impacted the society (topic) on their own without influencing each other. But experiment two focused on ballot items that represented different \textit{aspects} that jointly contributed to the same subject matter and may interact with one another, a typical case in the HCI domain. 
% We hypothesize that the latter case is more challenging for the participants to express accurately. Thus, if QV could outperform Likert in such cases, it will broaden the use cases for QV.
% Lastly, the second experiment focused on a setting that surveyed matters with a more tangible and immediate outcome to the participants, a common scenario in HCI studies, as opposed to matters with a more abstract and further-in-the-future impact. This difference may also impact the relative performance of QV and Likert. 
% Our last change made the second experiment a within-subject study to understand how the same individual's expression differs using different survey tools.
%<---------------------------->%
% HCI Experiment background
%% Video HCI experiments
%% Selection of the five elements and their definitions
%% The goal of this HCI experiment is to find elements that impact participants most.
%<---------------------------->%
% On the one hand, we wanted to avoid creating an entirely new HCI study that required sophisticated verification. On the other hand, reproducing a prior HCI study that used Likert surveys can be costly and difficult because of the limited access to the devices, designs, or interfaces used in the study. Therefore, we developed new research based on prior research but with a new research question and study design to maintain ecological validity.
% Participants rated the overall quality, video quality, audio quality, and enjoyment level  in each condition. The study derived the conclusions from analyzing the means and standard deviations of the Likert survey results. This HCI experiment is a typical study to explore which one or some of the $K$ elements to prioritize under constraints.
% Researchers provided insights to topics including multi-media conferencing \cite{watson1996evaluating}, video-audio perception \cite{chen2006cognitive, molnar2015assessing}, and, more specifically, trade-offs among various video and audio elements under network or monetary constraints \cite{molnar2013comedy, oeldorf2012bad}. understand how users with bandwidth constraints made trade-offs covering a broad set of elements across multiple videos and audio elements. They 
% There is no prior literature that looked at five combinations in a single experiment and studied them together, to the best of our knowledge. Hence, this is a valid HCI-related research question. We are also aware that these video elements' importance relies heavily on the type of video being served. 
% Video clips such as sports can contain specific jargon, while movie clips can be unfamiliar to some and not to others. a large amount of visualization but also provided information through speech. Drama and talk shows, for example, would lean towards visual elements or audio elements. Finally, visual and audio elements in a weather forecast complement each other. 
% answering the research question in identifying the video/audio elements that impact participants' streaming experience the most.
% In this tutorial, for each video element, we showed a pair of videos side-by-side for participants to compare how the same video would differ if a particular element were perfect and when the element is of lousy quality. 
% After experiencing the current prototype, the participants moved on to the next page.
% It is important to note that this interface is important because we asked participants to elicit preferences among the different \textit{perspectives} of the same subject matter. Each of these perspectives might not be independent of one another.
% We then instructed them to explore how various enhancement levels on different elements in the current prototype would improve their viewing experience. 
% This interface showcased a weather forecast video on the top of the page. 
% Participants can toggle any of these five elements to any of the four levels at any time. According to the quality levels the participants set, the video playback will immediately apply those changes. We .
% The instruction also told participants to consider that each element is associated with a cost, and the buyer will need to pay each element's cost. We told participants that if the buyer decides to purchase the product, they will receive 10\% of the final price they proposed as their commission. 
% This binary design prevents us from bounding participants' choices when provided a slider. 
% Notice that instead of giving participants the power to select the quality over various levels as they did in the video playground in step three. We only provide two qualities for each video element. 