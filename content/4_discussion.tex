\section{Discussion} \label{discussion}
In this section, we discuss implications from the two experiment results. In addition, we lay out many open questions discovered throughout this experiment.

\subsection{Does QV align better to true preferences?}
We begin our discussion by answering all three research questions. From the two experiments, we showed that QV aligned better to people's true preferences compared with Likert surveys under the following conditions: First, the question of the survey focused on making a decision among $K$ options, at least for societal and HCI surveys. Second, the QV survey must provide enough voice credits ($O(N^{3/2})$) to participants. Third, the survey options can be of different \textit{aspects} of the same subject matter or different \textit{options} for the same subject matter. Both experiments showed a significant effect size when comparing how QV and Likert aligned with individual behaviors. We believe that results from the experiments evident that QV can assist in decision making when surveying crowds.

The inherent difference between QV and Likert survey lies in the notion of costs when individuals express opinions. Likert does not carry costs. Any individual could elect any options, selecting extreme values for all of the survey questions if one preferred. This behavior is not possible in QV. QV participants must vote to represent their attitude for each option. These votes come with a quadratic cost. These costs confined participants' behaviors. One possible explanation of why constraints align better with individual behaviors is the concept of ``Scarcity Frames Value'', a work by \textcite{Shah2015a}. In this work, the authors showed that lower-income participants are less susceptible to context effects than higher-income participants. They attributed this phenomenon to that lower-income participants are better at trade-off thinking. In other words, under resource constraint conditions, individuals focus on what is needed and become more rational in decision making. We observe qualitative supports for this claim from experiment one, specifically when there is a change in voice credits. One participant (\texttt{P24194}), when completing the second QV survey in experiment one, experienced a drop in the number of voice credits, they mentioned, ``I had fewer credits, so each vote seemed more expensive.'' Voice credits translate the idea of ``scarceness'' and resource constraint into a survey.

Another difference between Likert and QV is the degree of freedom among choices. A five-point Likert survey provides only five choices, and a nine-point Likert survey provides exactly nine choices for each question. These choices limit the way a participant voice their opinion. One participant (\texttt{P9b3ae}) explicitly mentioned ``[\textellipsis] I would answer otherwise, if there were other options, such as not much, or a little bit.'' Participants wanted to express different attitudes because Likert surveys forced them to map their feelings onto a fixed scale. QV, in contrast, provides a more considerable degree of freedom. Participants can express their fine-grain preferences, as long as their cost does not exceed their given credits. 
Debates about the degree of freedom in Likert surveys exist in literature as early as 1965 \cite{komorita1965number}. This research showed that if the options are homogeneous, a two-point Likert scale yields as high-reliability coefficient as a multi-category system. The research also emphasized that reliability should not be the only metric when deciding which scale is better than the other scale, much more the opposite. It implies that a scale should be chosen for the purpose it aims to serve and the context it is used in. However, in modern research that utilize Likert surveys, there was often little to no discussions describing why the researchers used a specific type of Likert survey. 



\subsection{Open questions to QV}
It is not trivial yo compare Likert and QV with user's approximate true preferences. During the study, we identified various open questions that we yet to address. In this subsection, we list out these future directions.

\subsubsection{Aligning Ordinal Data With Scalar Values}
Analyzing ordinal Likert data has been a challenge ever since Likert was introduced. It is debatable whether our approach mapping Likert data to metric values is the best approach. At the same time, identifying the best measure to compare Likert results with QV is difficult. Future research could explore if there are alternatives to perform such a comparison that circumvents the challenge of mapping ordinal data. 

\subsubsection{Comparing other QV with other surveying methods}
In the previous subsection, we mentioned that Likert survey choices could limit individuals' degree of freedom to express their attitudes. One open question includes investigating if another type of Likert survey influences participants' behavior compared to QV. In addition, despite Likert survey considered one of the most used surveying technique, one might argue that instead of Likert, other voting mechanisms brings in the concept of resource constraint and preference elicitation such as but not limited to knapsack voting \cite{goel2015knapsack} and ranked-base voting \cite{ledo2018evaluation}. The difference between QV and knapsack voting lies in the way costs were calculated, where QV's votes cost grows quadratically and knapsack linearly. On the other hand, ranked-based voting does not show the magnitude of differences between individuals' options. However, comparing different voting methods with QV remains an open question.

\subsubsection{Upper bound of voice credits and options}
In experiment one, quantitative data showed that the performance of QV does not come through before reaching an excessive amount of voice credits, as we see that QV with 36 voice credits unperformed QV with 108 and 324 voice credits. Qualitatively, when participants were given fewer credits in their second QV survey, many participants voiced their need to make hard cuts. \texttt{P9e5e6} said, ``I think I covered the bare basics.'' and \texttt{Pe37f2} said, ``Less to go around, so had to knuckle down and allocate the most to what I think is most important.'' These responses suggest limited capacity when the participant's tried expressing their preferences, making results more alike with Likert surveys. When given increased voice credits in their second QV survey, we also observed that some participants expressed an increased degree of freedom to express their opinions. \texttt{Pcc4aa} reported, ``with more credits i can show what i really like.'' and \texttt{P2d9da} stated, ``Because now that I have a lot more credits, I felt that I could vote on more issues that mean something to me.'' These qualitative responses could explain why QV with more voice credit performed better in the first experiment. However, we did not identify an upper bound where too many voice credits start creating excessive cognitive loads to participants. How to identify \textit{what} number of voice credits to use is still an open question.

In addition to voice credits, this study did not identify upper bounds for the number of options on a QV survey. One can imagine the difficulty for QV participants to vote among hundreds or even thousands of survey options. In fact, a work by Iyengar et al. \cite{iyengar2000choice} observed that more choices might not necessarily bring more satisfaction to individuals. Humans are not good at making choices across an extensive array of options. Therefore, the same question lies: ``Is there a limit of how many options could be on a QV survey that remains high quality in data collection?''

\subsubsection{Generalizability to different forms of questions}
In this study, we did not examine the type of questions that work on QV and those that do not. Many other types of surveys made use of Likert surveys to make collective decisions. For example, surveys that consist of independent questions that do not connect with one another might not work well using QV. It remains unclear what exact questions work better than other types of problems when using QV.

\subsubsection{Mental models and Interface design}
The final open question is designing a simple, intuitive QV interface. When an individual vote using QV, much information could help the individual make decisions, such as the voice credits used and remained, how an individual allocated the voice credits, or the overall votes cast. How should the interface provide the voter with this information without transferring too much cognitive load? Besides, showing an individual how they had allocated their votes could also potentially interfere and encourage voters to vote for or against an option. Finally, we also need to investigate the QV interface for mobile and tablet devices. In fact, to generate a good design, we would also require studies on individuals' mental models of how they make decisions when casting votes under QV.

\subsection{Other implications}
It is critical to reaffirm that the goal of this study is not to claim one method superior or inferior to another. Instead, we want to understand if an alternative voting mechanism can assist better collective decision-making. QV aligns much closer to participants' true preference and provides much more information when making a collective decision in a 1 in $K$ setting. As aforementioned, there still exist many unexplored open questions to understand the nuances in QV.






% \subsection{Where are QV's limitations}
% Experiment two shows a slightly different and more nuanced result.
% It is important to know that
% the characteristics of the ballot options 
% are different compared to experiment one.
% On this ballot, the options are \textit{multiple aspects}
% of a same question.
% In other words, 
% one requires all options 
% to form the result of the final outcome.
% Let us use an analogy:
% If experiment one asks you
% ``how much do you prefer between
% coke, fries, and burgers'',
% the second experiment asks you
% ``how important do you think
% freshness, taste, and texture 
% of your beef patty are?''
% Notice the options in the first question 
% are independent while 
% those in the second question 
% collectively decide how good a beef patty is.

% From an intensity perspective 
% of the aggregated opinions, 
% qualitatively we can observe that 
% the preference result from QV aligns closer 
% to the true preference than that from Likert. 
% We have yet to examine its statistical significance 
% due to an experiment design limitation. 
% From a preference ranking perspective, 
% neither of the results from the Likert survey 
% and QV survey
% diverged significantly 
% from the incentive-compatible behaviors 
% that the buyback group demonstrated. 
% However, part of the Likert results 
% did diverge significantly from the QV results, 
% since aspects in Likert results clustered 
% in the higher rankings, 
% while aspects in the QV results 
% spread out more across the lower rankings. 
% Such finding echoes part of the conclusion 
% in the first experiment, 
% where QV is able to show finer-grained preference results 
% than Likert.

% In conclusion,
% we can conclude that QV with a sufficient budget outperforms Likert surveys when the survey aims to elicit preferences in a 1 in $K$ setting.
% There is not enough statistical evidence yet to conclude whether QV aligns to true preference better than Likert if the survey options are multiple aspects of the same subject. Nevertheless, both experiments demonstrated that QV elicits finer grain preferences from people than Likert in both cases, which is an advantage survey designer could leverage to gain more in-depth understanding of people's opinions.



% \subsection{Design Implications}
% Given these discussions, 
% we propose the following design implications. 
% First, QV provides more fine-grain results,
% including the preference and the level of intensity,
% a group has on a particular topic,
% when deciding among one in $K$ options.
% In the CSCW community,
% we believe this can be applied to 
% many collective decision-making processes.
% Form electing a great project among many,
% to redistributing limited resources among those in need,
% QV serves as an alternative tool 
% than traditional Likert surveys.
