\section{Discussion} \label{discussion}

\subsection{Does QV aligns better?}
The goal of this study is to 
experiment empirically whether
QV aligns closer to people's true preferences 
when compared to Likert surveys.
From the experiment results,
it shows that QV aligns better 
in certain scenarios.
One of the greatest difference
in experiment one and two
lies not only in the domain,
but also the relationships between
the options on the ballot.

In experiment one,
the $1$ in $K$ setting,
each of the presented options
are independent.
Even though resource constraints,
the final outcome of the decisions
is not immediate and does not require
strick combination of all options.
For example,
the society would not malfunction if ``art''
does not get the additional funds.
From the statistical results,
as long as the voice credits 
are more than $N^{3/2}$, where N is the number of options on the ballot,
QV aligns closer to people's true preferences
compared to Likert surveys.
We can likely attribute this result 
as Likert surveys are bounded by an ordinal scale 
that the survey conductor designed. 
From the freeform response text, we collected
with the experiment,
we see a few instances in the Likert group 
where participants would claim one or two options 
as the most critical social causes 
but electing ``very important'' for 
three or more options as their attitude.
% For example P09a47 mentioned, 
% ``I think the environment education 
% and healthcare should be our top priorities right now. 
% Other issues are also important 
%, but not as much so.''
% However, the participants filled out 
% Education, Environment, Health, and Human Services 
% as ``Very important.'' 
For example, Pd80fc mentioned, ``[I] think health and the environment are important'' while putting Pets and Animals, Arts, Culture, Humanities, Environment, and Veteran. as ``Very important.''
On top of the quantitative results,
these behaviors might explain the reason.
There might exist different levels of ``Very important.'' 
in participant's minds but was not able to express them expressively in the Likert surveys.
One participant (P9b3ae) explicitly mentioned ``[\textellipsis] I would answer otherwise, if there were other options, such as not much, or a little bit.''
Similar issues were not present in the QV Group responses.
Participants in the QV group were able to express more fine-grain preferences.
P1fee1 mentioned, ``I think health and human service are important and beneficial for society.'' while voting six votes for health and five votes for human services. This indicates that despite being ``important'', there is still a difference in weight and shadowed the limitation of Likert survey, where people can be limited by the options they were given.\par

One could argue that it is the design of Likert surveys that bounded the results, however,
a five or seven-point Likert survey can be viewed as the de facto method at collecting user attitudes.
It is usually little, if not no, discussion in research studies where it justifies the use of a five or seven-point Likert in the survey.
In fact, one related work discussed the use of different points in Likert surveys dated back to 1965 \cite{komorita1965number}. 
This research showed that if the options are homogeneous, a two-point Likert scale yields as high-reliability coefficient as a multi-category system.
The research also emphasized that reliability should not be the only metric when deciding which scale is better than the other scale, much more the opposite.
It implies that a scale should be chosen for the purpose it aims to serve and the context it is used in.
Similarly, it is important to emphasize that our claim is not to veto the use of Likert surveys, but to pose the alternative method, QV, that it aligns much closer to participants true preference and provides much more information when making a collective decision.\par

However, in experiment two,
we see a slightly different result.
In experiment two,
we took a step further 
and made ballot options for multiple aspects
of the same question.
Now these options lay on top of one another
To explain this subtle difference,
let us use an analogy.
If the experiment one asks you
``how much do you prefer between
coke, fries, and burgers'',
the second experiment asks you
``how important do you think
freshness, taste, and texture 
of your beef patty are?''
These options contribute
directly and collectively
to the final outcome
that is imminent.
When we look at the quantitative results of experiment two.
The results of the Likert survey and QV 
cannot significantly reflect the true behaviors that the buyback group demonstrated.
Especially when looking at how the three groups
rank their preferences,
both surveys fell short.
It is possible that
the intensity the QV displays
are close to the buyback outcomes
but we yet to derive quantitative support.
One possible reason is the characteristic 
that the options in this experiment pose.
The survey groups do not have as strong pressing
at determining the exact combination (importance)
the video elements are
compared to the third group of participants.

In conclusion,
we are comfortable that QV outperforms Likert surveys
when the survey aims to elicit one in $K$ options.
However, there is not enough evidence to support that
QV is able to demonstrate the same effect
if the options are multiple aspects of the same subject.

\subsection{Impact of QV voice credits}
In experiment one, we also confirmed our hypothesis that the number of voice credits does impact the results. 
In fact, given a fixed set of voice credits, there exists is a finite set of ways one could allocate their votes. 
Different from Likert surveys, the votes change according to the number of options present.
Yet, the performance of QV does not come through before reaching an excessive amount of voice credits, as we see that QV with 36 voice credits unperformed QV with 108 and 324 voice credits.

From the change in participant's responses as the number of voice credits changed, we found supporting evidence that participants require enough votes to demonstrate their preferences.
For example, some participants that had a drastic increase of voice credits, from 36 to 324 voice credits, expressed devoting some options that originally had zero votes. 
P2d9da stated, ``Because now that I have a lot more credits, I felt that I could vote on more issues that mean something to me.'' The participant initially only voted for Environment; however, with 324 votes, the participants voted for all but Faith and Spiritual. This supports our quantitative finding that a limited amount of voice credits suppressed the performance of QV. Participants also reported being freer and submitted more fine-grain opinions. As one participant (P54f23) responded: ``The greater voice quantity allowed me to vary the differences in choices'' more and similarly Pcc4aa reported, ``with more credits i can show what i really like.''
This reflects that additional credits pushed participants to express more fine-grain preferences.
% If the number of voice credits increased, as expected, some participants uniformly increased the number of votes across all nine options, stating that they try to be fair. Also, logically, other participants would devote the additional voice credits to the items of their likes or dislikes. 

On the contrary, participants are forced to downsize their preferences if credits decreased. Many participants voiced their need to make tradeoffs. P9e5e6 said, ``I think I covered the bare basics.'' and Pe37f2 said, ``Less to go around, so had to knuckle down and allocate the most to what I think is most important.'' 
Again, this means that it is crucial to have enough points if we want to reflect participant's preferences and they're intensity accurately.
The question of how to identify \textit{what} number of voice credits to use is still unknown.

\subsection{Making tradeoffs in QV}
One of the biggest advantages that QV poses is limiting the degree of freedom when participants fill out the survey.
A Likert survey is hard to translate the idea of ``scarceness'' into a survey because survey respondents can put extreme values for all options. 
QV forced participants to think across options. 
Even though voice credits are one single unit and do not carry any weight, when total voice credits increase, the value of each voice credit devalued, vice versa. P24194 stated, ``I had fewer credits, so each vote seemed more expensive.''
Participants are now forced to think, weighing in an underlying cost, when voting options, pushing it to align better with their donation behaviors.
This finding aligns with the physiological finding by \textcite{Shah2015a}
The researchers discovered that people are more rational when faced with scarcity and making tradeoffs become more salient in this situation.

\subsection{Design Implications}
Given these discussions,
we propose the following design implications.
First, QV provides more fine-grain results,
including the preference and the level of intensity,
a group has on a particular topic,
when deciding among one in $K$ options.
In the CSCW community,
we believe this can be applied to 
many collective decision-making processes.
Form electing a great project among many,
to redistributing limited resources among those in need,
QV serves as an alternative tool 
than traditional Likert surveys.
