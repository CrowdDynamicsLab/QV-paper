\section{Discussion} \label{discussion}
In this section, 
we discuss in-depth implications 
of both experiment results.
Based on the dicussions,
we propose a few design implications.

\subsection{Does QV align better to true preferences?}
The purpose of this study is to 
understand empirically if
QV aligns closer to people's true preferences 
compared to Likert surveys.
From the experiment results,
it showed that QV aligns better 
in certain scenarios.
In this subsection,
we try to explain when and possibly why
QV works or not in these specific scenarios.
We begin by revisiting the experiments.

One of the greatest difference
in experiment one and two
lies between the relationships of
the options on the ballot.
\lwt{do we want to mention any other potential reasons, such as domain, experiment design, etc.?}
In experiment one,
the $1$ in $K$ setting,
each of the presented options
are independent.
Notice the final outcomes 
of the decisions
is not immediate and 
the options \textit{contributes}
toward a single question.
For example,
the society would not malfunction if ``art''
does not get the additional funds.
From the statistical results, we conclude that QV aligns closer to people's true preferences
compared to Likert surveys
as long as the voice credits given
are more than $O(N^{3/2})$, where N is the number of options on the ballot.
We believe this is because of two reasons:
limitation of Likert options and
trade-off mechanism design in QV.
% We can potentially attribute this result 
% to Likert surveys being bounded by an ordinal scale determined by the survey designer, while QV surveys offered more freedom to express their opinions. 
% Based on the free-form-text response we collected after the participants completed a survey,

\subsubsection{Limitation of Likert Options}
First of all, 
Likert surveys are bounded by an ordinal scale 
that the survey conductor designed while QV is not.
This means that 
for QV participants,
there are a lot more ways
and degree of freedom
they can express
their fine-grain preferences.
From the free-form response text we collected
during the experiment,
one participant (\texttt{P9b3ae}) explicitly mentioned ``[\textellipsis] I would answer otherwise, if there were other options, such as not much, or a little bit.''
This shows support that
participants exist different levels of importance 
but were not able to express them expressively 
in the Likert surveys.
Similar issues were not presented
in the QV Group responses.

One could argue that it is the design of Likert surveys that bounded the results, however,
a five or seven-point Likert survey can be viewed as the de facto method at collecting user attitudes.
It is usually little, if not no, discussion in research studies where it justifies the use of a five or seven-point Likert in the survey.
In fact, one related work discussed the use of different points in Likert surveys dated back to 1965 \cite{komorita1965number}. 
This research showed that if the options are homogeneous, a two-point Likert scale yields as high-reliability coefficient as a multi-category system.
The research also emphasized that reliability should not be the only metric when deciding which scale is better than the other scale, much more the opposite.
It implies that a scale should be chosen for the purpose it aims to serve and the context it is used in.
Similarly, it is important to emphasize that our claim is not to veto the use of Likert surveys, but to pose an alternative method, QV, that aligns much closer to participants true preference and provides much more information when making a collective decision in a 1 in $K$ setting.

\subsubsection{trade-off mechanism design in QV}
The second reason is that
QV forces participants to make trade-offs.
Likert surveys does not impose cost 
on expressing strong opinions 
so people tend to exaggerate 
or try not as hard to distinguish. 
In other words,
a Likert survey is hard 
at translating the idea of ``scarceness'' 
into a survey 
because survey respondents can put extreme values 
for all options. 

we see a few instances in the Likert group 
where participants would claim one or two options 
as the most critical social causes in their text response 
but selecting ``very important'' for 
three or more options in the survey.
% For example P09a47 mentioned, 
% ``I think the environment education 
% and healthcare should be our top priorities right now. 
% Other issues are also important 
%, but not as much so.''
% However, the participants filled out 
% Education, Environment, Health, and Human Services 
% as ``Very important.'' 
For example, \texttt{Pd80fc} mentioned, ``[I] think health and the environment are important'' while putting Pets and Animals, Arts, Culture, Humanities, Environment, and Veteran. as ``Very important.''
However, we see people distinguishing the difference
among several important options.
P1fee1 mentioned, ``I think health and human service are important and beneficial for society.'' while voting six votes for health and five votes for human services. This indicates that despite being ``important'', there is still a difference in weight and shadowed the limitation of Likert survey, where people can be limited by the options they were given.

QV forced participants to think across options. 
Even though voice credits are one single unit 
and do not carry any weight, 
when total voice credits increase, 
the value of each voice credit devalued, 
vice versa. 
\texttt{P24194} stated, 
``I had fewer credits, so each vote seemed more expensive.''
Participants are now forced to think, weighing in an underlying cost, when voting options, pushing it to align better with their donation behaviors.
This finding aligns with the physiological finding by \textcite{Shah2015a}
The researchers discovered that people are more rational when faced with scarcity and making trade-offs become more salient in this situation.


\subsection{Where are QV's limitations}
Experiment two shows a slightly different and more nuanced result.
It is important to know that
the characteristics of the ballot options 
are different compared to experiment one.
On this ballot, the options are \textit{multiple aspects}
of a same question.
In other words, 
one requires all options 
to form the result of the final outcome.
Let us use an analogy:
If experiment one asks you
``how much do you prefer between
coke, fries, and burgers'',
the second experiment asks you
``how important do you think
freshness, taste, and texture 
of your beef patty are?''
Notice the options in the first question 
are independent while 
those in the second question 
collectively decide how good a beef patty is.

From an intensity perspective 
of the aggregated opinions, 
qualitatively we can observe that 
the preference result from QV aligns closer 
to the true preference than that from Likert. 
We have yet to examine its statistical significance 
due to an experiment design limitation. 
From a preference ranking perspective, 
neither of the results from the Likert survey 
and QV survey
diverged significantly 
from the incentive-compatible behaviors 
that the buyback group demonstrated. 
However, part of the Likert results 
did diverge significantly from the QV results, 
since aspects in Likert results clustered 
in the higher rankings, 
while aspects in the QV results 
spread out more across the lower rankings. 
Such finding echoes part of the conclusion 
in the first experiment, 
where QV is able to show finer-grained preference results 
than Likert.

In conclusion,
we can conclude that QV with a sufficient budget outperforms Likert surveys when the survey aims to elicit preferences in a 1 in $K$ setting.
There is not enough statistical evidence yet to conclude whether QV aligns to true preference better than Likert if the survey options are multiple aspects of the same subject. Nevertheless, both experiments demonstrated that QV elicits finer grain preferences from people than Likert in both cases, which is an advantage survey designer could leverage to gain more in-depth understanding of people's opinions.

\subsection{Impact of QV voice credits}
In experiment one, we also confirmed our hypothesis that the number of voice credits does impact the results. 
In fact, given a fixed set of voice credits, there exists is a finite set of ways one could allocate their votes. 
Different from Likert surveys, the votes change according to the number of options present.
Yet, the performance of QV does not come through before reaching an excessive amount of voice credits, as we see that QV with 36 voice credits unperformed QV with 108 and 324 voice credits.

From the change in participant's responses as the number of voice credits changed, we found supporting evidence that participants require enough votes to demonstrate their preferences.
For example, some participants that had a drastic increase of voice credits, from 36 to 324 voice credits, expressed devoting some options that originally had zero votes. 
\texttt{P2d9da} stated, ``Because now that I have a lot more credits, I felt that I could vote on more issues that mean something to me.'' The participant initially only voted for Environment; however, with 324 votes, the participants voted for all but Faith and Spiritual. This supports our quantitative finding that a limited amount of voice credits suppressed the performance of QV. Participants also reported being freer and submitted more fine-grain opinions. As one participant (\texttt{P54f23}) responded: ``The greater voice quantity allowed me to vary the differences in choices'' more and similarly \texttt{Pcc4aa} reported, ``with more credits i can show what i really like.''
This reflects that additional credits pushed participants to express more fine-grain preferences.
% If the number of voice credits increased, as expected, some participants uniformly increased the number of votes across all nine options, stating that they try to be fair. Also, logically, other participants would devote the additional voice credits to the items of their likes or dislikes. 

On the contrary, participants are forced to downsize their preferences if credits decreased. Many participants voiced their need to make trade-offs. \texttt{P9e5e6} said, ``I think I covered the bare basics.'' and \texttt{Pe37f2} said, ``Less to go around, so had to knuckle down and allocate the most to what I think is most important.'' 
Again, this means that it is crucial to have enough points if we want to reflect participant's preferences and they're intensity accurately.
The question of how to identify \textit{what} number of voice credits to use is still unknown.

\subsection{Design Implications}
Given these discussions, 
we propose the following design implications. 
First, QV provides more fine-grain results,
including the preference and the level of intensity,
a group has on a particular topic,
when deciding among one in $K$ options.
In the CSCW community,
we believe this can be applied to 
many collective decision-making processes.
Form electing a great project among many,
to redistributing limited resources among those in need,
QV serves as an alternative tool 
than traditional Likert surveys.
