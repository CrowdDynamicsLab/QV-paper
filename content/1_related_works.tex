\section{Related Works} \label{related_works}
In this section, 
we first explain the challenges
that Likert faces
and then describe related works of QV.

\subsection{Likert Scale Surveys}
Likert-scale survey, 
is a commonly used method 
to collects participant's opinions
because of its ease of use.
These surveys are deployed
to validate findings or clarify hypotheses
\cite{ozok2009survey, ledo2018evaluation} in HCI.
They are also used to verify or uncover the user's needs.
The original Likert scale surveys
were invented by Rensis Likert in 1932, 
which utilizes step-intervals 
from one attitude to the next 
on the scale \cite{likert1932technique}.
Researchers today design 3, 5, 7, 
or even 12-point Likert scale evaluation surveys to accommodate different uses
\cite{garland2008computer,finstad2010}.
In addition, these surveys
can also use verbal descriptions
to demonstrate an ordinal scale.
Some researchers even developed 
alternative forms of Likert scale 
such as slider scales \cite{roster2015exploring} 
or phrase completions \cite{hodge2003phrase}, 
which aimed to circumvent 
some of the shortcomings of the traditional Likert scale.

There are, however, widespread controversies in the community on
when, why, and how to use it \cite{bishop2015use}.
For instance, 
researchers can misuse statistical methods
, such as using mean and standard deviations \cite{jamieson2004likert},
to understand outcomes
when working with an ordinal metric.
Quantifying aggregated Likert scale surveys,
such as explaining what ``agree and a half'' means
can also be unclear.
Besides, 
as options on the survey can be stepwise,
one should not assume scales to be equally divided,
which can be confusing.
In other words, 
strongly agree and agree can be different compared to
neutral and agree \cite{jamieson2004likert, edmondson2005likert}.

An empirical study by \textcite{quarfoot2017quadratic}
identified another challenge
where people exaggerate their views
when filling out political surveys.
In this study,
participants often express strong polarized opinions
or have no opinion at all,
making it hard to form optimal conclusions\cite{posner2018radical}.
% When the results were aggregated, 
% a ``W'' shape distribution.
%This distribution demonstrated how people stand upon polarized views,
This occurrence was 
theoretically proved by \textcite{cavaille2018towards},
where respondents tend to overstate their values
if they want to influence the results through the survey.
These challenges motivated us 
to understand whether QV can fill the gap
and provide a more accurate measurement
for collective decision making.\par

\subsection{Quadratic Voting}
Quadratic voting originated 
with the argument
that current one-person-one-vote system
can easily bias toward the majority's opinion
and omitting the minority's votes\cite{posner2018radical}.
This phenomenon is termed as the tyranny of the majority
where the democratic decision 
does not take care of those in need.
In other words, these types of voting
does not allow fine-grain responses
to the options they were to vote \cite{sep-voting-methods}.
Some voting mechanisms tried to resolve this
by introducing rank-based voting 
in which voters would decide
how they rank the options
while submitting their opinions.
This mechanism can however
suffer from Condorcet's paradox 
where results can be suboptimal 
because the ranks of the voters
might not be transitive\cite{sep-voting-methods}.
Many other voting mechanisms suffer from similar issues.

This triggers the development of Quadratic Voting
created by \textcite{posner2018radical}. 
to overcome traditional voting challenges .
QV tries to capture a cost 
for the voter when he or she
made a particular decision by voting toward specific options.
This "price-taking" equilibrium helps
participants maximizes their utility using their votes.
This is theoretically proven by \textcite{lalley2018quadratic}
and showed that there exists an approximate structure of Bayes-Nash equilibria.

In order for QV to capture the voice of the minority
and allocate the correct cost to the votes
QV has the following mechanism:
Consider collecting $N$ participants voting,
each participant is entitled to 
$K$ voice credits.
Participants can express their binary opinion 
(for or against)
each option$o_i$ within a set of options $O$ listed on the ballot. 
Participants can purchase any number of votes $v_i \in \mathbb{R}$
vetted toward any of the options $o_i$.
However, to vote $v_i$ votes toward $o_i$,
participants have to spend $v_i^2$ voice credits,
billed toward their $k$ credits.
The outcome of QV 
would be the ranks of the sum
among the total votes for any option $\sum{V_{oi}}$
across all $N$ participants.

To use an analogy,
Suppose every voter has a bank account 
with a fixed amount of money, say 100 dollars.
On a ballot, there are ten statements.
Voters can now buy votes using their money in the account.
However, for each statement, the cost of the votes
increases quadratically. 
For example, voting two fors on the first option 
would cost the voter four votes;
voting three against on the fifth option 
costs the voter nine votes, and so on.
This means that the more votes one devote to an option,
the more costly it is to do so,
forgoing the opportunity the voter had
to vote for other options.

\subsection{QV in the wild}
After QV was proposed,
\textcite{quarfoot2017quadratic} conducted an 
empirical study to understand how 
QV results compare to Likert scale surveys.
They recruited 4500 participants 
to survey an individual's opinions
across ten public policy
using either Likert-style questionnaire, QV survey, or both.
The study found that the number of people
who voted for the same number of votes
for the options 
distributed normally and consistently across all options.
This differs from results from Likert scaled surveys 
completed from the same group of participants,
where results are either heavily skewed 
or polarized ``W-shaped''distribution.
Researchers also saw individuals 
spent more time expressing their opinion
and reveal a more fine-grain attitude 
toward the policies.
Thus, the study concludes that 
QV provides a clearer picture 
of public opinion to policymakers
\cite{quarfoot2017quadratic}.

The work by Quarfoot et al., however,
only used mean and z-scores,
to compare the final aggregated results 
across the two methods.
In addition, 
the design on the policies 
have a strong tendency for voters
to agree or disagree on the extreme,
such as one's opinion on ``same-sex marriage''.
Thus, little do we know if
QV produces different results 
than Likert scale surveys
if the options are less competitive,
for example, choosing one's favorite ice cream flavor.\par
% For example, if we are looking at 
% preference elicitation where the group aims to choose
% one among $K$ options.

Another empirical study was applied to education 
by \textcite{naylor2017first}. 
The author again used QV and Likert
to understand essential elements 
among a list of factor
that impacts students' success in universities.
Results showed that QV provided more insights, 
such as distinguishing good-to-have factors from must-have elements.
These factors are not heated debated controversies
compared to public policies in the previous studies and 
they are independent elements that do not require 
students to make trade-offs.
For example, students can have a sense of ``belonging'' and
a sense of ``achievement'' at the same time.

To the best of our knowledge,
there does not exist an empirical study 
that focused on investigating
how QV and Likert perform
under the condition of selecting
one in $K$ options.
% Do note that these trade-offs need not be polarizing topics
% but rather where each option is interconnected
% and can impact one from the other.
This setting was recently discussed 
in a theoretical work by \textcite{eguia2019quadratic},
who claims that QV is still in favor 
of resolving budget-constrained 
for risk natural agents
to figure out an efficient decision 
across multiple alternatives
as a collective choice problem.
We aim to complete this missing piece of the puzzle.
Further,
we are not aware of any work
that studies alignment between
participants' actual beliefs
and QV surveys.
Existing research pointed out 
possible fallacy exists with self-reporting
\cite{araujo2017much, vavreck2007exaggerated}.
Thus, we aim to understand
how QV and Likert scale surveys
align with the agent's true beliefs.
We also want to test
whether the total number of voice credits 
impacted the results of QV.
Finally, we believe that
no HCI research utilized QV
to form design decisions.