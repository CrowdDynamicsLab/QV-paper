\section{Related Work} \label{related_works}

\subsection{Likert Survey}
Likert surveys are forms that collected participants' level of agreement or disagreement of the given subject matter using step-intervals from one attitude to the next attitude on a scale \cite{likert1932technique}. Invented by psychologist Rensis Likert in 1932, he used a five-point Likert survey to collect individuals' perspectives on controversial societal questions. The initial design of Likert surveys with polarized scale assisted survey conductors in identifying clusters of individuals for their belief \cite{joshi2015likert}. 

Since then, Likert surveys grew its popularity and became widely adopted. People credit this success to its ease of use across domains. Researchers also started using 3, 5, 7, or even 12-point Likert scale evaluation surveys \cite{garland2008computer,finstad2010} on top of the original design. Likert-scaled surveys soon moved on to ordinal scales that use adjectives that describe the degree of status. Some researchers even developed alternative forms of Likert scale such as slider scales \cite{roster2015exploring} or phrase completions \cite{hodge2003phrase}, which aimed to circumvent some shortcomings of the traditional Likert scale.

While these improvements were helpful, there were widespread controversies in the community on when, why, and how to use Likert surveys \cite{bishop2015use}. For instance, researchers sometimes misuse statistical methods, such as calculating mean and standard deviations \cite{jamieson2004likert}, to understand outcomes when Likert responses are ordinal. Ordinal responses should not draw inference through these statistical tools because these response values are unquantifiable. For example, ``agree and a half'' does not exist in real life. Further, one should not assume scale intervals to be equal when Likert surveys use stepwise options. In other words, ``strongly agree'' to ``agree'' might not scale the same as ``neutral'' to ``agree'' \cite{jamieson2004likert, edmondson2005likert}.

An empirical study \cite{quarfoot2017quadratic} identified another challenge where people exaggerated their views when filling out political surveys. In this study, participants would either expressed polarized opinions or refrained from voicing an opinion, making survey creators hard to form optimal consensus \cite{posner2018radical}. \textcite{cavaille2018towards}  proved this occurrence theoretically; if respondents want to influence the outcome of the survey using their survey response, they will exaggerate their values.

These challenges might not come directly from the Likert survey mechanisms, but Likert survey mechanisms influenced how people used it. This phenomenon motivated us to understand whether QV can provide a more truthful measurement for collective decision making.\par

\subsection{Quadratic Voting}
Voting is another method that facilitates consensus among a group of people. There exist different voting methods which facilitates different purposes. Most of these methods offer each voter one vote followed by a different mechanism to form a consensus. The majority rule and unanimity rule, for example, declare the winner based on whether an option received over half of the voter population or the number of voters, respectively. This type of voting rules are straightforward but suffers from allowing voters to express more fine-grain options\cite{sep-voting-methods}. Other methods like rank-based voting enable voters to express the ranks of the candidate options when submitting the votes. The drawback of all these voting methods lies in how each voter only has one vote. This characteristic made these voting methods suffer from the tyranny of the majority and Condorcet's paradox \cite{sep-voting-methods}. The tyranny of the majority occurs when the majority of the population favors one option over the other, limiting the voice of the minority. Condorcet's paradox happens if voter's ranked-choice were not transitive then the results might be suboptimal.

To overcome these challenges \cite{posner2018radical}, Weyl at al. developed Quadratic Voting (QV), a collective decision-making mechanism \cite{lalley2018quadratic}. Inspired by the Vickrey-Clarke-Groves mechanism \cite{roughgarden2010algorithmic}, QV inherits the concept where individuals have to pay the cost that the others lost from that outcome rather than merely allowing the highest bidder to win the goods \cite{posner2018radical}. \textcite{lalley2018quadratic} proved theoretically that in this case of Bayes-Nash equilibrium, the total welfare loss converges as the population increases when using QV.\par

% QV relies on a ``price-taking'' equilibrium of the survey ``market.'' Assuming rational agents, each participant attending the survey will try to maximize their utility. This utility is to use the least amount of vote to gain a preferable outcome. For any given agent, if they favor one option on the survey, their final utility would be the utility of the option minus the cost of the votes plus the average cost of the votes from all other participants that voted for this option. If the agent is not in favor of an option, the negative utility would be the loss of the cost of the votes plus the average cost of the votes from all other participants that voted for this option. The goal is to minimize the aggregated welfare loss across all the participants. Lalley et al. \cite{lalley2018quadratic} proved theoretically that in this case of Bayes-Nash equilibrium, the total welfare loss converges as the population increases when using QV.\par

Here we formally define QV. Consider collecting responses from $N$ participants, and each participant is entitled to express a binary opinion (for or against) for each option $o_i$ within a set of options $O$. Participants are also entitled to $K$ credits of a given currency and can choose to purchase any number of votes $v_i \in \mathbb{R}$ for any $o_i$, by paying $v_i^2$ from that $K$ credits. The result of the QV can be generalized by the ranks of the sum among the total votes for an option $\sum{V_{oi}}$ across all $N$ participants.\par

After proposing QV, Quarfoot et al. \cite{quarfoot2017quadratic} conducted an empirical study to understand how QV results compare to Likert surveys. They surveyed 4500 participant's opinions across ten public policy, using either a Likert survey, QV, or both. The study found that the number of people who voted the same number of votes for any particular option follows a normal distribution when using QV. This  differs from the Likert surveys results, which among the same group of participants, the collected data were heavily skewed or polarized ``W-shaped'' distributions. Researchers inferred that QV is better at expressing the participant's opinion for polarized statements. Researchers also saw individuals spent more time expressing their opinion and reveal a more fine-grain attitude toward the list of policies. Thus, the study concludes that QV provides a clearer picture of public opinion to policymakers \cite{quarfoot2017quadratic}.

This work by Quarfoot et al. relied on the mean and z-scores to draw qualitative conclusions across the two methods. We argue that comparing both measures required more rigorous quantitative analysis to gain a deeper understanding of their differences. The study showed Liekrt and QV derived \textit{different} results, but it did not describe how both methods derived results compared to participant's truthful preferences. Besides, the study focused on controversial policies that have a strong tendency for voters to agree or disagree on the extreme, such as asking one's opinion on ``same-sex marriage''. Little do we know if QV produces different results than Likert surveys if the options are less competitive, for example, choosing one's favorite ice cream flavor.\par

Another empirical study applied QV to the field of education by Naylor et al. \cite{naylor2017first}. The author used QV and Likert surveys to understand essential elements among a list of factors that impacted students' success at universities. Results showed that QV provided more insights, such as distinguishing good-to-have from must-have factors. Even though these factors are not heated debated controversies compared to public policies in the previous studies, each of these elements is independent variables that do not require students to make trade-offs. For example, students can have a sense of ``belonging'' and a sense of ``achievement'' simultaneously.

To the best of our knowledge, there was no existing empirical work that focused on investigating how QV and Likert perform under the condition of selecting one in $K$ options. A recent theoretical work discussed in a similar setting by Eguia et al. \cite{eguia2019quadratic} focused on the collective choice-making problem. This work claimed that QV is in favor of helping an organization, assuming risk natural agents, figure out an efficient decision across multiple alternatives when the budget is constrained. We aim to complement this missing piece of the puzzle through an empirical study. Further, we are not aware of any work that studies alignment between participants' actual beliefs through their behaviors with QV surveys. Existing research pointed out possible fallacy exists with current self-reporting surveying techniques \cite{araujo2017much, vavreck2007exaggerated}. Thus, we aim to understand how QV and Likert surveys aligned with the agent's true beliefs instead of merely comparing the outcomes of Likert surveys with QV. Further, these related works did not reveal how they designed the voice credits in their experiments. Therefore, we also want to test whether the total number of voice credits impacted the results of QV. 

%% Old text from thesis %%
% Though the Likert scale's original design was five options, there is no finite definition of how many options there should be on a Likert-scale survey.
% The original experiment focused on a finite and symmetric set of options on the scale for clustering. 
% For example, researchers deployed these surveys to validate findings or clarify hypotheses \cite{ozok2009survey, ledo2018evaluation} in HCI. Alternatively, Likert surveys help uncover user's needs.


%% Old draft related work %%
% \subsection{Likert Surveys} Likert surveys are commonly deployed to collects participant's opinions because of its ease of use. These surveys are deployed to validate findings or clarify hypotheses \cite{ozok2009survey, ledo2018evaluation} in HCI. They are also used to verify or uncover the user's needs. Likert surveys were invented by \textcite{likert1932technique}  in \citeyear{likert1932technique}, which utilized a scale to deploy step-intervals  from one attitude to the next. Researchers today design 3, 5, 7,  or 12-point Likert surveys to accommodate different uses \cite{garland2008computer,finstad2010}.
% In addition, these surveys can use verbal descriptions to segment the intervals, presenting the choices with an ordinal scale. Researchers looked at alternative presentations of the Likert scale such as slider scales \cite{roster2015exploring}  and phrase completions \cite{hodge2003phrase} to circumvent shortcomings of the traditional Likert scale. 
% While many efforts tried to improve the popular Likert surveys, there are widespread controversies in the community on when, why, and how to use Likert surveys \cite{bishop2015use}. For instance,  researchers sometimes misuse statistical method, such as using mean and standard deviations \cite{jamieson2004likert}, to understand outcomes when working with an ordinal metric. Aggregated ordinal scale Likert surveys is  unquantifiable because ``agree and a half''  simply does not exist in real life. Further,  one should not assume scale intervals to be equal when Likert surveys uses stepwise options. In other words, ``strongly agree'' to ``agree'' might not scale the same as  ``neutral'' to ``agree''  \cite{jamieson2004likert, edmondson2005likert}. 
% An empirical study by \textcite{quarfoot2017quadratic} identified another challenge where people exaggerate their views when filling out political surveys. In this study, participants often express polarized opinions or have no opinion at all, making it hard to form optimal conclusions \cite{posner2018radical}. % When the results were aggregated,  % a ``W'' shape distribution. %This distribution demonstrated how people stand upon polarized views, This occurrence was  theoretically proved by \textcite{cavaille2018towards}, assuming respondents want their survey response to influence the results, they always have the tendency to overstate their values. 
% These challenges motivated us  to understand whether QV can fill the gap of inaccuracy and provide a more accurate measurement for collective decision making.\par 
% \subsection{Quadratic Voting} Voting is often exercised for collective decision making. Quadratic voting originated  from the argument that current one-person-one-vote (1p1v) system can easily bias toward the majority's opinion and omitting the minority's votes. This phenomenon is termed as  the ``Tyranny of the Majority'' which criticizes that democratic decision can easily neglect those in need  \cite{posner2018radical}.
% In addition, 1p1v suffers the inability for individuals to express fine-grain opinions on the options one voted \cite{sep-voting-methods}. Ranked-based voting tried to resolve this by allowing voters to rank the options. This mechanism can suffer from Condorcet's paradox  where results can be suboptimal  because the ranks of the voters might not be transitive\cite{easley2012networks, sep-voting-methods}. 
% This motivated the development of Quadratic Voting created by \textcite{posner2018radical}.  to overcome traditional voting challenges. QV captures the cost a voter has to pay when they made a particular voting decision. It regulates the votes by assigning different level of prices given a fix budget. This "price-taking" equilibrium helps participants vote by maximizing their utility. This is theoretically supported by \textcite{lalley2018quadratic} and showed that there exists an approximate structure of Bayes-Nash equilibria. 
% In order for QV to capture the voice of the minority and allocate the correct cost to the votes, QV established the following mechanism: Consider collecting votes from $N$ participants, each participant is entitled to  $K$ voice credits. Participants can express binary opinion (for or against) each option $o_i$ acorss a set of options $O$ listed on the ballot.  Participants can purchase any number of votes $v_i \in \mathbb{R}$ vetted toward any of the options $o_i$. However, to vote $v_i$ votes toward $o_i$, participants have to spend $v_i^2$ voice credits, billed toward their $k$ credits. The outcome of QV  would be the ranks of the sum among the total votes for any option $\sum{V_{oi}}$ across all $N$ participants. 
% To use an analogy, suppose every voter has a bank account  with a fixed amount of money, say 100 dollars. On a ballot, there are ten statements. Voters can now buy votes using their money in the account. However, for each statement, the cost of the votes increases quadratically.  For example, voting two fors on the first statement  would cost the voter four dollars; voting three against on another statement  costs the voter nine dollars, and so on. This means that the more votes one devote to an option, the more costly it is. Voting more votes on one statment,  forgoes the opportunity to vote for other options. Here, the money referes to the voice credit in QV. 
% \subsection{QV in the wild} After proposing QV, \textcite{quarfoot2017quadratic} conducted an  empirical study to understand how  QV results compare to Likert surveys. They surveyed 4500 participants  on individuals' opinions across ten public policy using either a Likert survey, QV, or both. The study found that the number of people who voted for the same number of votes for any particular option  follows a normal distribution when using QV. This differ from the Likert surveys, which among the same group of participants, returned heavily skewed  or polarized ``W-shaped'' distributions. Researchers inferred  QV provides is better at expressing the participant's opinion for polarized statements. Researchers also saw individuals  spent more time expressing their opinion and reveal a more fine-grain attitude  toward the policies. Thus, the study concludes that  QV provides a clearer picture  of public opinion to policymakers \cite{quarfoot2017quadratic}.

% The work by \textcite{quarfoot2017quadratic}, however, only used mean and z-scores, to compare the final aggregated results  across the two methods. In addition,  the design on the policies  have a strong tendency for voters to agree or disagree on the extreme, such asking one's opinion on ``same-sex marriage''. Thus, little do we know if QV produces different results  than Likert surveys if the options are less competitive, for example, choosing one's favorite ice cream flavor.\par % For example, if we are looking at  % preference elicitation where the group aims to choose % one among $K$ options. 
% Another empirical study was applied to  the field of education  by \textcite{naylor2017first}.  The author used QV and Likert survey to understand essential elements  among a list of factor that impacts students' success in universities. Results showed that QV provided more insights,  such as distinguishing good-to-have factors from must-have elements. Even though these factors are not heated debated controversies compared to public policies in the previous studies,  each of these elements are independent variables that does not require students to make trade-offs. For example, students can have a sense of ``belonging'' and a sense of ``achievement'' at the same time. 
% To the best of our knowledge, there does not exist an empirical study  that focused on investigating how QV and Likert perform under the condition of selecting one in $K$ options. % Do note that these trade-offs need not be polarizing topics % but rather where each option is interconnected % and can impact one from the other. This setting was recently discussed  in a theoretical work by \textcite{eguia2019quadratic} focusing on collective choice-making problem. This work claimed that QV is in favor  to help an organization, assuming risk natural agents, figure out an efficient decision  across multiple alternatives when budget is constrained. We aim to complete this missing piece of the puzzle  through an empirical study. Further,
% we are not aware of any work that studies alignment between participants' actual beliefs and QV surveys. Existing research pointed out  possible fallacy exists  with current self-reporting surveying techniques \cite{araujo2017much, vavreck2007exaggerated}. Thus, we aim to understand how QV and Likert surveys aligned with the agent's true beliefs instead of simply comparing  the outcomes of Likert surveys with QV. We also want to test whether the total number of voice credits  impacted the results of QV. Finally, we believe that no HCI research utilized QV to form design decisions. 