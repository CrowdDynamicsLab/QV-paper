\section{Related Work} \label{related_works}

\subsection{Limitations in Likert scale surveys}
Likert scale is an intensity scale used to elicit participants' level of agreement, satisfaction, and perceived importance \cite{likert1932technique}. Invented by psychologist Rensis Likert in 1932, the initial design of Likert scale aimed to identify clusters of opinions within a crowd \cite{joshi2015likert}. A Likert scale survey started with a 5-point scale \footnote{The original design used: Strongly Approve (1), Approve (2), Undecided (3), Disapprove (4), Strongly Disapprove (5) as the five scales.}, and researchers that followed developed an array of variations with 3, 7, 11, or 12-point Likert scale \cite{garland2008computer,finstad2010}. Some researchers developed alternative forms of Likert scale interfaces such as slider scales \cite{roster2015exploring} or phrase completions \cite{hodge2003phrase} to improve usability from the traditional Likert scale survey. 

Likert scale surveys have grown in popularity since they are easy to understand and administer across domains. However, as a ratings approach, Likert scale has its limitations. The primary limitation is not able to accurately understand how participants' prioritize a set of options due to several response biases, a phenomenon where survey respondents' stated opinions do not align with their true opinions. 

Likert scale surveys suffer from ``acquiescence bias,'' a type of response bias where participants tend to select the same level across the entire survey \cite{alwin1985measurement, moors2016two}. To minimize this bias, researchers typically design the same ratio of positively and negatively framed options \cite{kuru2016improving}. 

Another type of bias, ``extreme responding,'' happens when participants only answer on the extreme ends of the Likert scale \cite{batchelor2016extreme, furnham1986response, meisenberg2008acquiescent}, misaligned with their true preferences. An empirical study by \textcite{quarfoot2017quadratic} observed this phenomenon --- participants either expressed polarized opinions or did not express an opinion at all, making it hard for survey creators to form an optimal strategy based on the survey responses \cite{posner2018radical}. \textcite{cavaille2018towards} provided a theoretical explanation for this bias; respondents exaggerate their opinions on purpose to influence the outcome of the survey. Researchers have developed statistical methods and suggested best practices for better question designs to mitigate such biases \cite{glaser2008response}.

Although researchers have designed various solutions to alleviate these response biases stemmed from the \textit{mechanism} of Likert scale, in this work, we examine QV as a potential alternative that is less prone to these response biases.

\subsection{Quadratic Voting}
\textcite{posner2018radical} developed Quadratic Voting (QV), a collective decision-making mechanism \cite{lalley2018quadratic} to circumvent the tyranny of the majority in traditional one-person-one-vote mechanisms, where the majority favors one option over the rest, always limiting the voice of the minority. Since participants in QV are not bound to a single vote, QV does not have such a concern. Inspired by the Vickrey-Clarke-Groves mechanism \cite{roughgarden2010algorithmic}, in QV, \tc{the marginal cost to cast an additional vote grows proportionally to the votes already cast on that option, inducing rational participants to vote proportionally to how much they care about an issue \cite{posner2018radical}.} This is why, unlike many traditional voting methods, each QV vote comes with a quadratic cost. 

% 
% if an individual wanted to pivot the outcome in QV, they need to pay twice as much voice credits then an opponent's costs. For example, if one participant voted for an issue at two votes (three marginal voice credits), another individual would need to spend seven more voice credits (twice as much as four) than the first participants to win the outcome.
% was designed with the concept that if an individual wants to pivot the outcome in their favor through their votes, they should pay twice as much voice credits at the margin then someone else's costs

% Most voting mechanisms derived outcomes by aggregating the \textbf{single} vote across individual voters. For example, majority rule declares the winner for the option that received over half of all votes. Yet, such mechanism could result the tyranny of the majority, where the majority of the population favors one option over the rest, limiting the voice of the minority. Since participants in QV were not bound to a single vote, QV does not have such a concern.

Here we formally define QV. Consider collecting responses from $S$ participants, where each person has access to a fixed number of voice credits $B$ to allocate across options. Then, each person can cast more than one vote (for, or against) for each option, with the proviso that the votes have a quadratic cost. Thus, casting $n_k$ votes on option $k$ would cost $c(n_k) \propto n_k^2$ in voice credits. Furthermore, the total cost in voice credits across all options cannot exceed the budget $B$. Therefore, a person casting positive or negative votes across $k$ options has to satisfy $\sum_k n_k^2 \leqslant B$, where $n_k$ is the number of votes cast on option $k$. At last, survey creators analyze the aggregated results by comparing the total number of votes from all participants across each option. 

Several works explored the theoretical properties of QV. \textcite{lalley2018quadratic} proved theoretically that QV's total welfare loss converges as the number of respondents increases. Similarly, a recent theoretical work by \textcite{eguia2019quadratic} proved theoretically that the probability that the QV results arriving at a socially efficient outcome converged to one as the number of participants increased in a resource-constrained survey. ~\textcite{Lalley2018} also proved \textit{robust optimality} properties of QV, suggesting that QV may be incentive-compatible (i.e., truth-telling is the dominant strategy for the respondent). Our study examines if QV can elicit incentive-compatible results from an empirical lens instead of a theoretical lens. We next discuss empirical studies that compared QV with Likert scale.

\subsection{Comparing QV with Likert Scale}
Since QV is a relatively new voting mechanism, we are only aware of two studies that empirically compared QV with Likert scale. Both of these studies focused on comparing the characteristics of responses from QV and Likert scale surveys.

\textcite{quarfoot2017quadratic} surveyed 4500 participants on their opinions for ten public policies; each participant completed either a Likert scale survey, a QV survey, or both.  The study found that, for the same group of participants, responses on any option from the QV survey followed a normal distribution while those from the Likert scale survey were heavily skewed or polarized into ``W-shaped'' distributions. Researchers also noticed that individuals deliberated their responses more in QV and revealed more fine-grained attitudes. Thus, the study concluded that QV provided a clearer picture of the crowd's opinions to policy-makers on polarized issues \cite{quarfoot2017quadratic}. 

Even though the study showed that the Likert scale survey and the QV survey produced \textit{different} results, it did not compare the survey results to the participants' true preferences. Our study takes one step further and compares their degree of alignment with participants' true preferences. Besides, the study focused on controversial policies, such as ``same-sex marriage'', on which voters had a strong tendency to agree or disagree at the extremes. It's unclear how QV and Likert perform when survey options are less polarized, e.g., choosing one's favorite ice cream flavor. Our study analyzes this latter scenario.
% This work by Quarfoot et al. relied on the mean and z-scores to draw qualitative conclusions across the two methods. We argue that comparing both measures required more rigorous quantitative analysis to gain a deeper understanding of their differences. 

In another empirical study, \textcite{naylor2017first} utilized QV for an educational research to understand students' opinions towards a list of factors that impacted their success at universities. Results showed that QV provided more insights than the Likert survey, such as distinguishing good-to-have factors from must-have ones. Again, our study differs from this work as we focus on comparing the accuracy of survey responses.
% For example, students can have a sense of ``belonging'' and a sense of ``achievement'' simultaneously.

Overall, to the best of our knowledge, prior work has neither studied the degree of alignment between QV responses and participants' true preferences, nor compared it with the degree of alignment between Likert responses and true preferences. Therefore, our work is the first to examine QV's ability to elicit true preferences.

% no existing empirical study that investigates how QV and Likert results align with people's true preferences when the survey goal is to choose among $K$ options of one topic. Furthermore, we are not aware of any work that studied the alignment between participants' actual beliefs through their behaviors with QV surveys. Thus, we aim to understand how QV and Likert scale surveys aligned with the agent's true beliefs instead of merely comparing the outcomes of Likert scale surveys with QV. 

% where the final outcomes were derived by, for example the  where the mechanism is to aggregate the number of vote each voter casts, there is a cost for QV participants. Traditional 
% Voting is another method that facilitates collective decision-making among crowds. Different voting mechanisms  differently. The majority rule and unanimity rule, for example,  or all votes cast, respectively. One-person-one-vote is a straightforward mechanism but suffers from allowing voters to express more fine-grain options \cite{sep-voting-methods} and 
% Another voting methods, such as rank-based voting, enable voters to express the ranks of the candidate options when submitting the votes. This mechanism can suffer Condorcet's paradox \cite{sep-voting-methods} where voter's ranked-choice were not transitive and an aggregation of votes brings suboptimal results.





% While these improvements are helpful, there have been widespread controversies in the community on when, why, and how to use Likert surveys \cite{bishop2015use}. For instance, researchers sometimes misuse statistical methods, such as calculating mean and standard deviations \cite{jamieson2004likert}, which are inappropriate for characterizing ordinal data. For example, if is hard to map the mean of ``agree and a half'' to a real life attitude. Further, one should not assume scale intervals to be equal when Likert surveys use stepwise options. In other words, ``strongly agree'' to ``agree'' might not scale the same as ``neutral'' to ``agree'' \cite{jamieson2004likert, edmondson2005likert}.


% These challenges might not come directly from the Likert survey mechanisms, but Likert survey mechanisms influenced how people used it. This phenomenon motivated us to understand whether QV can provide a more truthful measurement for collective decision making.\par


% To the best of our knowledge, there was no existing empirical work that focused on investigating . 
% We aim to complement this missing piece of the puzzle through an empirical study. Further, we are not aware of any work that studies alignment between participants' actual beliefs through their behaviors with QV surveys. Existing research pointed out possible issues with current self-reporting surveying techniques \cite{araujo2017much, vavreck2007exaggerated}. Thus, we aim to understand how QV and Likert surveys aligned with the agent's true beliefs instead of merely comparing the outcomes of Likert surveys with QV. Further, these related works did not reveal how they designed the voice credits in their experiments. Therefore, we also want to test whether the total number of voice credits impacted the results of QV. 



%Existing research pointed out possible issues with current self-reporting surveying techniques \cite{araujo2017much, vavreck2007exaggerated}. 
%Further, these related works did not reveal how they designed the voice credits in their experiments. Therefore, we also want to test whether the total number of voice credits impacted the results of QV. 


% QV relies on a ``price-taking'' equilibrium of the survey ``market.'' Assuming rational agents, each participant attending the survey will try to maximize their utility. This utility is to use the least amount of vote to gain a preferable outcome. For any given agent, if they favor one option on the survey, their final utility would be the utility of the option minus the cost of the votes plus the average cost of the votes from all other participants that voted for this option. If the agent is not in favor of an option, the negative utility would be the loss of the cost of the votes plus the average cost of the votes from all other participants that voted for this option. The goal is to minimize the aggregated welfare loss across all the participants. Lalley et al. \cite{lalley2018quadratic} proved theoretically that in this case of Bayes-Nash equilibrium, the total welfare loss converges as the population increases when using QV.\par
%% ======================== %%

%% Old text from thesis %%
% Though the Likert scale's original design was five options, there is no finite definition of how many options there should be on a Likert-scale survey.
% The original experiment focused on a finite and symmetric set of options on the scale for clustering. 
% For example, researchers deployed these surveys to validate findings or clarify hypotheses \cite{ozok2009survey, ledo2018evaluation} in HCI. Alternatively, Likert surveys help uncover user's needs.


%% Old draft related work %%
% \subsection{Likert Surveys} Likert surveys are commonly deployed to collects participant's opinions because of its ease of use. These surveys are deployed to validate findings or clarify hypotheses \cite{ozok2009survey, ledo2018evaluation} in HCI. They are also used to verify or uncover the user's needs. Likert surveys were invented by \textcite{likert1932technique}  in \citeyear{likert1932technique}, which utilized a scale to deploy step-intervals  from one attitude to the next. Researchers today design 3, 5, 7,  or 12-point Likert surveys to accommodate different uses \cite{garland2008computer,finstad2010}.
% In addition, these surveys can use verbal descriptions to segment the intervals, presenting the choices with an ordinal scale. Researchers looked at alternative presentations of the Likert scale such as slider scales \cite{roster2015exploring}  and phrase completions \cite{hodge2003phrase} to circumvent shortcomings of the traditional Likert scale. 
% While many efforts tried to improve the popular Likert surveys, there are widespread controversies in the community on when, why, and how to use Likert surveys \cite{bishop2015use}. For instance,  researchers sometimes misuse statistical method, such as using mean and standard deviations \cite{jamieson2004likert}, to understand outcomes when working with an ordinal metric. Aggregated ordinal scale Likert surveys is  unquantifiable because ``agree and a half''  simply does not exist in real life. Further,  one should not assume scale intervals to be equal when Likert surveys uses stepwise options. In other words, ``strongly agree'' to ``agree'' might not scale the same as  ``neutral'' to ``agree''  \cite{jamieson2004likert, edmondson2005likert}. 
% An empirical study by \textcite{quarfoot2017quadratic} identified another challenge where people exaggerate their views when filling out political surveys. In this study, participants often express polarized opinions or have no opinion at all, making it hard to form optimal conclusions \cite{posner2018radical}. % When the results were aggregated,  % a ``W'' shape distribution. %This distribution demonstrated how people stand upon polarized views, This occurrence was  theoretically proved by \textcite{cavaille2018towards}, assuming respondents want their survey response to influence the results, they always have the tendency to overstate their values. 
% These challenges motivated us  to understand whether QV can fill the gap of inaccuracy and provide a more accurate measurement for collective decision making.\par 
% \subsection{Quadratic Voting} Voting is often exercised for collective decision making. Quadratic voting originated  from the argument that current one-person-one-vote (1p1v) system can easily bias toward the majority's opinion and omitting the minority's votes. This phenomenon is termed as  the ``Tyranny of the Majority'' which criticizes that democratic decision can easily neglect those in need  \cite{posner2018radical}.
% In addition, 1p1v suffers the inability for individuals to express fine-grain opinions on the options one voted \cite{sep-voting-methods}. Ranked-based voting tried to resolve this by allowing voters to rank the options. This mechanism can suffer from Condorcet's paradox  where results can be suboptimal  because the ranks of the voters might not be transitive\cite{easley2012networks, sep-voting-methods}. 
% This motivated the development of Quadratic Voting created by \textcite{posner2018radical}.  to overcome traditional voting challenges. QV captures the cost a voter has to pay when they made a particular voting decision. It regulates the votes by assigning different level of prices given a fix budget. This "price-taking" equilibrium helps participants vote by maximizing their utility. This is theoretically supported by \textcite{lalley2018quadratic} and showed that there exists an approximate structure of Bayes-Nash equilibria. 
% In order for QV to capture the voice of the minority and allocate the correct cost to the votes, QV established the following mechanism: Consider collecting votes from $N$ participants, each participant is entitled to  $K$ voice credits. Participants can express binary opinion (for or against) each option $o_i$ acorss a set of options $O$ listed on the ballot.  Participants can purchase any number of votes $v_i \in \mathbb{R}$ vetted toward any of the options $o_i$. However, to vote $v_i$ votes toward $o_i$, participants have to spend $v_i^2$ voice credits, billed toward their $k$ credits. The outcome of QV  would be the ranks of the sum among the total votes for any option $\sum{V_{oi}}$ across all $N$ participants. 
% To use an analogy, suppose every voter has a bank account  with a fixed amount of money, say 100 dollars. On a ballot, there are ten statements. Voters can now buy votes using their money in the account. However, for each statement, the cost of the votes increases quadratically.  For example, voting two fors on the first statement  would cost the voter four dollars; voting three against on another statement  costs the voter nine dollars, and so on. This means that the more votes one devote to an option, the more costly it is. Voting more votes on one statment,  forgoes the opportunity to vote for other options. Here, the money referes to the voice credit in QV. 
% \subsection{QV in the wild} After proposing QV, \textcite{quarfoot2017quadratic} conducted an  empirical study to understand how  QV results compare to Likert surveys. They surveyed 4500 participants  on individuals' opinions across ten public policy using either a Likert survey, QV, or both. The study found that the number of people who voted for the same number of votes for any particular option  follows a normal distribution when using QV. This differ from the Likert surveys, which among the same group of participants, returned heavily skewed  or polarized ``W-shaped'' distributions. Researchers inferred  QV provides is better at expressing the participant's opinion for polarized statements. Researchers also saw individuals  spent more time expressing their opinion and reveal a more fine-grain attitude  toward the policies. Thus, the study concludes that  QV provides a clearer picture  of public opinion to policymakers \cite{quarfoot2017quadratic}.

% The work by \textcite{quarfoot2017quadratic}, however, only used mean and z-scores, to compare the final aggregated results  across the two methods. In addition,  the design on the policies  have a strong tendency for voters to agree or disagree on the extreme, such asking one's opinion on ``same-sex marriage''. Thus, little do we know if QV produces different results  than Likert surveys if the options are less competitive, for example, choosing one's favorite ice cream flavor.\par % For example, if we are looking at  % preference elicitation where the group aims to choose % one among $K$ options. 
% Another empirical study was applied to  the field of education  by \textcite{naylor2017first}.  The author used QV and Likert survey to understand essential elements  among a list of factor that impacts students' success in universities. Results showed that QV provided more insights,  such as distinguishing good-to-have factors from must-have elements. Even though these factors are not heated debated controversies compared to public policies in the previous studies,  each of these elements are independent variables that does not require students to make trade-offs. For example, students can have a sense of ``belonging'' and a sense of ``achievement'' at the same time. 
% To the best of our knowledge, there does not exist an empirical study  that focused on investigating how QV and Likert perform under the condition of selecting one in $K$ options. % Do note that these trade-offs need not be polarizing topics % but rather where each option is interconnected % and can impact one from the other. This setting was recently discussed  in a theoretical work by \textcite{eguia2019quadratic} focusing on collective choice-making problem. This work claimed that QV is in favor  to help an organization, assuming risk natural agents, figure out an efficient decision  across multiple alternatives when budget is constrained. We aim to complete this missing piece of the puzzle  through an empirical study. Further,
% we are not aware of any work that studies alignment between participants' actual beliefs and QV surveys. Existing research pointed out  possible fallacy exists  with current self-reporting surveying techniques \cite{araujo2017much, vavreck2007exaggerated}. Thus, we aim to understand how QV and Likert surveys aligned with the agent's true beliefs instead of simply comparing  the outcomes of Likert surveys with QV. We also want to test whether the total number of voice credits  impacted the results of QV. Finally, we believe that no HCI research utilized QV to form design decisions. 