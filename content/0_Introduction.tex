\section{Introduction}
Likert scale survey 
is one of the most widely used methods
to obtain the participant's opinion
in the realm of human-computer interaction.
Survey participants would express
a rating across a series of measurements ---
\textit{Very agree to very disagree} or
\textit{On a scale of 1 to 5} ---
for a listed statement.
Very often, 
these opinions help
researchers or decision-makers
uncover consenses 
across a group of people.

However, there had been findings of
how researchers can 
easily misuse Likert scale surveys
either applying incorrect analysis methods 
\cite{bishop2015use}
or misinterpreting the analysis results
\cite{jamieson2004likert, pell2005use}
leading to questionable findings.
In addition, 
many research papers
do not explain the rational
behind the use of 
Likert scale surveys.
In a community that adopted Likert scale surveys
almost as the defacto standard,
we ask a fundamental question: 
``Is Likert-scale survey the ideal method
to measure collective attitudes for decision making?''

We begin by exploring one type of question
in collective decision making that aims To
elicit user preferences among $K$ options.
Research agencies, industry labs or independent researchers
often want to understand how to better allocate resources.
For example, 
ordinal scale polls were designed
to understand public opinions
on government policy \cite{pew}
because there is limited funding.
Companies deploy online surveys 
to understand how product users 
feel about the features and services
that needs further improvements
because companies have limited time 
to develop the next release.
Physical surveys can be found 
in shopping centers 
to collect an individual's experiences
for products on the shelf
because there are limited shelves.
All these examples demonstrated
how surveys are often tied to 
making decisions 
by gathering consensus
from surveying individual's attitudes.

In this study, 
we look at an alternative method
called Quadratic Voting (QV).
Published in 2015,
\textcite{posner2018radical}
proposed Quadratic voting
as a voting mechanism 
with approximate Pareto efficiency.
Under this voting mechanism,
voters were initially given 
a fixed amount of voice credits (VC).
With the credits, 
individuals can purchase 
any number of votes to support any of the statements
listed on the ballot.
However, the cost of each vote 
increases quadratically 
when voted toward the same option.
The authors proved that this 
mechanism is more efficient 
at making a collective decision 
because it minimizes welfare loss.
Since 2015, a few studies
compared Likert scaled surveys with QV 
empirically and theoretically
\cite{quarfoot2017quadratic, naylor2017first}.
\textcite{cavaille2018towards} argues that 
QV outperforms Likert-scale surveys 
among a set of political and economic issues.
Despite these findings,
we are not aware of related works that
compare Likert scale surveys and QV
with participants' underlying true preferences.
Therefore, it is unclear whether or not
and in what degree
does QV results align with participants' behaviors.
In addition, 
no current work, to the best of our knowledge,
deployed QV in the area of HCI.

To be more specific, 
we ask the following research questions:
\begin{enumerate}[label={},leftmargin=\parindent]
    \item RQ1. How does results from 
               QV, Likert scaled survey
               align with people's behavior 
               when surveying societal issues?
    \item RQ2. How does results from 
               QV, Likert-scale 
               align with people's behavior 
               when placed in an HCI context?
    \item RQ3. How do different amounts of
               voice credits impact results of QV empirically?
    \item RQ4. What are some qualitative insights that can be observed
               when participants vote under QV?
\end{enumerate}
To answer these research questions,
we designed two experiments.
The first experiment,
designed to answer RQ1 and RQ3,
is a between-subject study
where participants express their attitudes
among a set of societal causes using 
QV and Likert-scaled surveys
and then donate
to organizations relevant to these organizations.
The second experiment 
created an HCI study environment,
aimed to answer RQ2,
where participants were asked about 
opinions among different video elements
and their opinions using QV and Likert-scaled surveys.
Our results showed that both experiments support
QV in providing a clean and efficient way
compared to Likert scale surveys
at eliciting participant's true preferences.

\textbf{Contributions}
Our work made several contributions to the research community. 
First, we proved empirically 
the use of QV outperforms Likert scale survey
when conducting ``choosing one in $K$'' experiments.
Second, we showed that the usability of QV
is transferrable from a generic domain to HCI.
Third, we designed a bayesian model 
that facilitates the comparison
of Likert scale surveys, QV, and behaviors.
Fourth, we developed an online experiment
to mimic real-life HCI-related decision making.
And finally, we provided the source code of our easy to deploy, 
interactive web platform for QV to the community.

\textbf{Design Implication}
TODO. Talk about interface, future work and insights.