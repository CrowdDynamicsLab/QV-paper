\subsection{Experiment 1 Quantitative Analysis Results} \label{results-1-quan}
In this section, we will first present descriptive statistics of the raw data in our first experiment. Then, we will explain our feature engineering and data transformation process based on the raw data. Lastly, we will introduce the Bayesian Model we applied in our analysis and present the analysis results.

\subsubsection{Descriptive Statistics of the Raw Data}
% -- raw data
%     describe the dataset, total # of participants in each group before and after dataset cleaning, demographics of each group;
    
Overall, we collected 223 complete responses in the first experiment. We removed 4 responses after checking the quality of the responses due to reasons such as not answering the qualitative question seriously or misunderstanding the prompt. Among the 219 remaining responses, 56 completed the Likert path, and the rest were distributed relatively evenly across the remaining 6 paths with various orders of QV, ranging from 24 to 28 responses per path. Aggregating responses from all 6 paths, the number of responses we got for QV with 36 credits (QV36), QV with 108 credits (QV108) and QV with 324 credits (QV324) were 107, 108, and 111 respectively. (To-do: maybe add a hierarchical graph the represents how responses from different paths are aggregated)

We recruited the participants with the goal of constructing a sample that was representative of the US census data in terms of age and education level. Having a representative sample is in particularly critical in our study because these voting and survey tools should aim to be designed for the general population. Based on Table \ref{fig:demo_exp1}, all the groups closely followed the demographics of the US population in both age and education level. This ensured that our results were not biased to a certain subgroup of the population, which is generally hard to achieve in MTurk studies without specific control. 

\begin{figure}[htpb]
    \centering
    \includegraphics[width=0.7\textwidth, keepaspectratio=true]{content/image/demographics_table.png}
    \caption{
        Sample Demographics Statistics Compared to US Census Data (Will fix into a table later)
    }
    \Description[Sample Demographics Statistics Compared to US Census Data for experiment 1]{Sample Demographics Statistics Compared to US Census Data for experiment 1}
    \label{fig:demo_exp1}
\end{figure}
    
%     donation descriptive statistics: perc of non-zero donation, total donation amount comparison across groups, donation distribution across topics between groups

In this experiment, each set of survey responses by a participant in a condition could be matched to the set of donation decisions made by the same participant. Since we would like to use the donation outcome of a participant as a proxy of his/her true preferences across the nine charity topics, we could only do so with participants that donated a non-zero amount of money. Therefore, we further filtered the dataset to keep only the responses that had a non-zero total donation amount. Across all the conditions, the average non-zero donation rate was 73.3\%, consistent with the results provided by Fehr and Gintis in 2007 \cite{fehr2007human}, which suggested that about 30\% of the population would always free-ride in public goods provision regardless of what others do. The donation rate in each condition closely centered around the average donation rate, ranging from 70.37\% (in QV108) and 77.19\% (in Likert). The number of valid responses after this step for Likert, QV36, QV108, and QV324 were 44, 76, 76 and 84 respectively.

Among those who donated a non-zero amount, participants exhibited different behaviors when deciding how much to donate in total. As shown in Figure \ref{fig:total_don_exp1}, there were two main clusters for the total donation amount. The first cluster centered around \$9-12 and most data points in this cluster lied within the range of \$5 to \$20. This group of people, making up about 60\% of the entire sample, donated part of the lottery winning amount but still kept a significant portion for themselves. The second cluster was between \$33 to \$35, suggesting that this group of people chose to contribute almost the full amount of the lottery prize. There were approximately 25\% of the participants who behaved this way. In most cases, the distribution pattern across conditions were relatively consistent, except that there were almost twice the proportion of participants in the Likert condition that donated almost the full amount compared to the other QV conditions. One possible explanation for the difference would be that the amount of effort required to complete the Likert condition was much lower than that of QV, and participants felt less tempted to earn extra reward for their time spent in the Likert condition. Overall, we found that the total amount of donation per participant was large enough to be distributed across charities in a way that could represent the full picture of his/her underlying true preferences for nine topics.

\begin{figure}[htpb]
    \centering
    \includegraphics[width=\textwidth, keepaspectratio=true]{content/image/total_contributions_across_conditions.pdf}
    \caption{
       Distributions of Total Donation Amounts across Conditions
    }
    \Description[Distributions of Total Donation Amounts across Groups for experiment 1]{Distributions of Total Donation Amounts across Groups for experiment 1}
    \label{fig:total_don_exp1}
\end{figure}

Given the aggregated total donation amount across all the participants in each condition, the amount was distributed to the nine charities in a highly varying manner as shown in Figure \ref{fig:topic_don_exp1}. The environment-related, health-related, and human-related charities were consistently the most popular ones among all the options in different groups, while the art-related, international-related, and faith-related ones were always the least popular. However, we could see some differences in the population-level preferences towards charities across the four conditions. For example, the pets-related charity received far less donation in percentage than the three QV groups. This suggests that there was a good amount of variance in people's opinions towards the nine topics, making the surveying task meaningful.

\begin{figure}[htpb]
    \centering
    \includegraphics[width=\textwidth, keepaspectratio=true]{content/image/normalized_contributions_per_topic_across_conditions.pdf}
    \caption{
      Percentage Contribution Amount per Topic with Respect to the Total Donation Amount across Conditions
    }
    \Description[Percentage Contribution Amount per Topic with Respect to the Total Donation Amount across Conditions for experiment 1]{Percentage Contribution Amount per Topic with Respect to the Total Donation Amount across Conditions for experiment 1}
    \label{fig:topic_don_exp1}
\end{figure}

%     QV & Likert votes descriptive statistics: votes distribution per topic across groups, budget usage distribution across QV groups

Figure \ref{fig:likert_exp1} shows how Likert responses distribute at the aggregated level across the nine topics. With a 5-point Likert scale, we can see that most topics have a distribution that skews towards positive opinions, with a median of "Important" and "Very Important". Even though the medians of six out of nine topics are all "Important", the shapes of their distributions are different, suggesting different levels of support by the participants. The sufficient amount of variations shown across topics indicates that our prompt in the experiment that asked participants to be aware of the resource constraint and express their relative preferences worked as intended. 

\begin{figure}[htpb]
    \centering
    \includegraphics[width=0.4\textwidth, keepaspectratio=true]{content/image/likert_distribution_per_topic.pdf}
    \caption{
      Distribution of Likert Responses per Topic. Each level from -2 to 2 corresponds to Very unimportant, Unimportant, Neutral, Important, and Very important.
    }
    \Description[Distribution of Likert Responses per Topic for experiment 1]{Distribution of Likert Responses per Topic for experiment 1}
    \label{fig:likert_exp1}
\end{figure}

Comparing across the three QV surveys, the response distributions are similar but have subtle differences. Consistent with prior work in QV \cite{quarfoot2017quadratic}, most distributions of all the topics are close to a Normal distribution. Looking only at the median of a distribution, the result from QV36 has less variation than those from QV108 and QV324, and resembles that from the Likert survey more. The medians of QV108 and QV324, on the contrary, clearly show nuanced differences across topics. Distributions in QV324 have longer tails than those in QV108, suggesting that participants did make use of the increased credits to express more extreme opinions at higher costs. A further examination in the percentage voice credits budget usage in three QV conditions (Figure \ref{fig:qv_budget_exp1}), we found that there was no decrease in the median percentage usage as the budget size increased (all around 98\%), but the tail of lower percentage usage in QV324 was longer than in the other two cases. This finding suggests that the extra credits provided to the participants were put to good use in most cases, and that participants were still comfortable with completing a QV survey with a large budget up to the order of $N^2$ ($N$ is the number of options in a survey) and complicated calculations with our QV interface. % mention the implication of longer tail in QV324 in discussion section: need to be aware of using an overly large budget and resulting in a worse tail

\begin{figure}[htpb]
    \centering
    \includegraphics[width=\textwidth, keepaspectratio=true]{content/image/qv_distribution_per_topic.pdf}
    \caption{
      Distribution of QV Responses per Topic in QV36, QV108 and QV324. The maximum possible number of votes on a topic was 6 votes in QV36, 10 votes in QV108, and 18 votes in QV324.
    }
    \Description[Distribution of QV Responses per Topic for experiment 1]{Distribution of QV Responses per Topic for experiment 1}
    \label{fig:qv3_exp1}
\end{figure}


\subsubsection{Opinions Alignment Measurement Calculation}
% -- data transformation to alignment measurement
%     describe the calculation of cosine similarity angle theta
%     mention our test of checking if other factors impact total donation amount -> absolute vs. normalized donation amount
%     show histogram and other descriptive statistics of the angle data

To answer our research question of how align Likert and QV survey responses are with people's true opinions reflected by their incentive-compatible (to-do: is it accurate to use this term here?) behavior, we need to design a metric that can measure the degree of alignment between the two. Before discussing about our choice of metric, we need to clarify the definition of "alignment" used here. Our definition of having a perfect alignment between a set of survey response and a set of donation amount by the same individual is that the individual expresses preferences with the same relative strength in both cases. Formally, it is defined as the following:\\

\begin{quote}
    A set of survey response $\vec{v} = [v_1, v_2, ..., v_n]$, and a set of donation amount $\vec{d} = [d_1, d_2, ..., d_n]$, where $n$ is the number of topics or options involved in the decision, are perfectly align if there exists a positive constant $k>0$ that satisfies $k\vec{v} = \vec{d}$.
\end{quote}

Our alignment focused on the relative strength in opinion for two reasons. First, the results from our four sets of surveys and the donation task were not on the same scale. For example, the maximum possible number of votes on a topic in QV36 is 6 while the maximum donation amount on a topic is \$35. Second, given two participants with the same opinion across the nine topics, their total amount of donation may still differ due to other factors such as income level, level of education, etc. Even if both of them split their total donation amounts in the same way proportionally, their absolute donation amounts across the topics would be different. Hence, we decided to care only about the relative strength in opinions across topics.

The metric for measuring the degree of alignment thus need to be monotonic with respect to the amount of discrepancy between two preference vectors in terms of relative strength in preferences. It would be preferable if the metric is easily interpretable. With these two criteria in mind, we decided to use the angle $\theta$ in the Cosine similarity metric as the alignment metric. It is formally defined as the following: \\

\begin{quote}
    The Cosine similarity angle $\theta$ between a set of survey response $\vec{v} = [v_1, v_2, ..., v_n] \in \mathbb{R}^n$, and a set of donation amount $\vec{d} = [d_1, d_2, ..., d_n] \in \mathbb{R}^n$, where $n$ is the number of topics or options involved in the decision, is calculated via $\theta = \frac{180}{\pi} \arccos{\frac{\vec{v} \cdot \vec{d}}{\|\vec{v}\| \|\vec{d}\|}}$, and $0\deg \leq \theta \leq 180\deg$.
\end{quote}

Cosine similarity is a commonly used similarity metric that measures the cosine of the angle between two non-zero vectors \cite{singhal2001modern}. It only provides information about the relative orientation of the two vectors and does not take into account the magnitude of the vectors. The angle of the Cosine similarity measures the same thing but represents it in terms of the angle degree, instead of a value between 0 and 1, which makes it more intuitive for interpretation. The definition of the angle of Cosine similarity fits our need perfectly. It is monotonic with respect to how different the orientations of the two vectors are, i.e., the relative strength in opinions, and does not care about the magnitude of the vectors, i.e., absolute vote or donation amount. Two sets of perfectly align opinions will yield a Cosine similarity angle of zero, while two sets of completely opposite opinions will result in an angle of 180 degree.

To compare the degree of alignment between the survey results from Likert, QV36, QV108, QV324 and their corresponding truthful preferences reflected in the donation task, our first step was to compute a Cosine similarity angle for each participant in each group. For the Likert group, we computed the Cosine similarity angle of a vector of Likert responses (between -2 and 2 for each topic) and a vector of the absolute donation amount of the same individual. In the 3 QV conditions, the angle is between a vector of QV votes and a vector of the absolute donation amount of the same participant. The next step that completes our analysis is setting up a Bayesian Model for these four sets of Cosine similarity angle per condition as described in the next subsection.


\subsubsection{Bayesian Formulation}
% -- Bayesian formulation
%     why Bayesian
%     the type of analysis question
%     choice of the likelihood function
%     choice of prior distributions

Given the four sets of Cosine similarity angle under Likert, QV36, QV108 and QV324 conditions respectively, we employed a Bayesian formulation of the problem to compare the degree of alignment between pairs of the conditions. In a recent paper, Kay et al. \cite{kay2016researcher} 

    
% -- Results analysis
%     Tools: PyMC3, MCMC, NUTS
%     Describe fitted values & convergence (trace plots)
%     Describe effect size analysis for comparing Likert and QV
%     Describe effect size analysis for comparing across QVs
    
\subsection{Experiment 1 Qualitative Analysis Results}\label{results-1-qual}
We ask participants to provide a freeform text response on the reason why they made the choices they made
when participants filled out the Likert scale survey or QV survey,
Of all surveys ($N=394$) across both groups, most participants filled out the surveys ($N=331$) based on what they think are the most important issues to them. %84 percent
Besides, a small portion of participants ($N=30$) used their instincts when replying to the survey.
Some participants either think that every aspect is important ($N=7$) or that resources should be equally distributed ($N=7$).

